{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80af9482",
   "metadata": {},
   "source": [
    "<H1>COMP4531 Deep Learning Mid-Term</H1>\n",
    "\n",
    "### Amy Schneider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53f9bc",
   "metadata": {},
   "source": [
    "In this project, we will be developing a basic neural network from the ground up to classify various types of fashion items. The primary objective of this project is to gain a comprehensive understanding of neural network architecture, including its theory and implementation details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f36f4",
   "metadata": {},
   "source": [
    "<H2>Part 0: Initialization</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da766f3",
   "metadata": {},
   "source": [
    "To start, let's load some packages and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5a0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that you don't need any other packages for this mid-term\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "random.seed(42) # NEVER change this line; this is for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684c8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "data = pd.read_csv('./fashion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffe85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data pre-processing is done for you. Please do NOT edit the cell\n",
    "# However, you should understand what these codes are doing\n",
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:400].T\n",
    "Y_dev = data_dev[-1]\n",
    "X_dev = data_dev[0:n-1]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[400:m].T\n",
    "Y_train = data_train[-1]\n",
    "X_train = data_train[0:n-1]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4a17f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 6, ..., 6, 2, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f23900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c9b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c2151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 785\n"
     ]
    }
   ],
   "source": [
    "print(m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec10f7",
   "metadata": {},
   "source": [
    "<H2>Part 1: Building your own neural network</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a070079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a global variable specifying the number of hidden neurons after the first layer\n",
    "# not the best practice, but we will do it for this mid-term project\n",
    "num_hidden_neurons = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f133d",
   "metadata": {},
   "source": [
    "This is the main part of the mid-term. You **must not** change the definition of the function. In fact, the comments are going to help you go through the implementation and they are all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ec06a",
   "metadata": {},
   "source": [
    "<H3>1.1 Initialize the parameter in the neural network</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa30c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters in the neural network\n",
    "\n",
    "# Based on the figure above, we need the weight and bias matrices. \n",
    "# W1, b1 are the matrices for the first layer\n",
    "# W2, b2 are the matrices for the second layer\n",
    "\n",
    "# You should think about the sizes of the matrices\n",
    "# then initialize elements in the matrix to be random numbers between -0.5 to +0.5\n",
    "\n",
    "    # np.random.rand generates random values from a uniform distribution between 0 and 1,\n",
    "    # subtracting 0.5 shifts this distribution to be between -0.5 and 0.5\n",
    "\n",
    "def init_params():\n",
    "    \n",
    "    # Number of input features\n",
    "    input_size = X_train.shape[0]\n",
    "    \n",
    "    # Number of classes in the classification task (as outlined in COMP4531_Mid-Term_Project.pdf)\n",
    "    output_size = 10\n",
    "    \n",
    "    # Initialize parameters for the first layer (W1, b1):\n",
    "    \n",
    "    # W1: weights (num_hidden_neurons x input_size) initialized between -0.5 and 0.5.\n",
    "    W1 = np.random.rand(num_hidden_neurons, input_size) - 0.5\n",
    "    # b1: biases (num_hidden_neurons x 1) initialized between -0.5 and 0.5.\n",
    "    b1 = np.random.rand(num_hidden_neurons, 1) - 0.5\n",
    "    \n",
    "    # Initialize parameters for the second layer (W2, b2):\n",
    "    # W2: weights (output_size x num_hidden_neurons) initialized between -0.5 and 0.5.\n",
    "    W2 = np.random.rand(output_size, num_hidden_neurons) - 0.5\n",
    "    # b2: biases (output_size x 1) initialized between -0.5 and 0.5.\n",
    "    b2 = np.random.rand(output_size, 1) - 0.5\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e02886",
   "metadata": {},
   "source": [
    "<H3>1.2 Implement the non-linearity functions and its derivatives</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fec893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a starting point, you only need a ReLu function, its derivative, and the softmax function \n",
    "\n",
    "def ReLU(Z):\n",
    "    # Computes the Rectified Linear Unit (ReLU) activation for each element in Z\n",
    "    # Parameters: Z (numpy array) - linear transformation output\n",
    "    # Returns: A (numpy array) - ReLU activation\n",
    "    \n",
    "    A = np.maximum(0, Z)\n",
    "    return A\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    # Computes the derivative of the ReLU activation for each element in Z\n",
    "    # Parameters: Z (numpy array) - linear transformation output\n",
    "    # Returns: dA (numpy array) - derivative of ReLU activation\n",
    "    \n",
    "    dA = np.where(Z > 0, 1, 0)\n",
    "    return dA\n",
    "\n",
    "def softmax(Z):\n",
    "    # Computes the softmax activation for each element in Z\n",
    "    # Parameters: Z (numpy array) - linear transformation output\n",
    "    # Returns: A (numpy array) - softmax activation\n",
    "    \n",
    "    exp_Z = np.exp(Z - np.max(Z))  # Subtracting max(Z) for numerical stability\n",
    "    A = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    \n",
    "    # Your code here\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e8de8",
   "metadata": {},
   "source": [
    "<H3>1.3 Implement the forward propagation function</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8b9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the forward propagation function, X is the inputs (the image in vector form), and we pass all the weights and biases\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    \n",
    "    # First layer\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = ReLU(Z1)  # Apply ReLU activation to first layer\n",
    "    \n",
    "    # Second layer\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)  # Computes the softmax activation for each element in Z\n",
    "    \n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc732fd3",
   "metadata": {},
   "source": [
    "<H3>1.4 Implement the backward propagation function</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60edcfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one hot function is to convert a numeric number into a one-hot vector\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.max() + 1, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "\n",
    "    return one_hot_Y\n",
    "\n",
    "# Now performing the backward propagation\n",
    "# Each function is only one line, but lots of Calculus behind \n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    \n",
    "    # Convert target labels Y into one-hot encoded vectors\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    # Get number of training examples\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    # Backward pass for second layer\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    # Backward pass for first layer\n",
    "    dZ1 = np.dot(W2.T, dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    # Return gradients for updating parameters\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Finally, we are ready to update the parameters\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    \n",
    "    # Update each parameter using learning rate (alpha) and its corresponding gradient (from backward_prop)\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa112e7c",
   "metadata": {},
   "source": [
    "<H3>1.5 Performing the gradient descent</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dbc5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the helper function. We need to convert the softmax output into a numeric label \n",
    "# This is done through get_predictions function\n",
    "def get_predictions(A2):\n",
    "    # Get index of maximum value along each column (axis=0)\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "# We also want to have a simple function to compute the accuracy. Notice that \"predictions\" and \"Y\" are the same shape\n",
    "def get_accuracy(predictions, Y):\n",
    "    # Calculate accuracy by comparing predicted labels with true labels\n",
    "    accuracy = np.mean(predictions == Y) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Finally, we are ready to implement gradient descent\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    \n",
    "    # Initialize parameters using init_params()\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Perform forward propagation\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        \n",
    "        # Perform backward propagation\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        \n",
    "        # Update parameters\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "        # Print accuracy every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            # print(get_accuracy(predictions, Y)) # original code\n",
    "            accuracy = get_accuracy(predictions, Y)\n",
    "            print(\"Accuracy: {:.2f}%\\n\".format(accuracy)) # Reformatted to show as percent and space out iterations\n",
    "\n",
    "    # Return the final trained parameters\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98227fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 12.12%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 39.56%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 53.25%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 58.69%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 61.94%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 63.94%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 65.94%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 67.12%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 68.44%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 69.50%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 70.19%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 71.19%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 72.12%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 72.44%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 71.31%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 71.81%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 72.56%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 73.06%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 73.88%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 73.88%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 74.31%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 74.81%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 75.06%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 75.12%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 76.12%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 76.75%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 77.19%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 77.44%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 77.56%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 77.88%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 78.31%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 78.75%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 79.00%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 79.31%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 79.69%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 79.94%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 80.12%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 80.62%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 80.81%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 81.12%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 81.31%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 81.62%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 81.81%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.00%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 82.00%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 82.25%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 82.50%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 82.62%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 82.88%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 82.94%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500) # original code\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 501) # To include interation 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fd141",
   "metadata": {},
   "source": [
    "<H3>1.6 Validation Set Performance</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0a8684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9fe33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83cd53",
   "metadata": {},
   "source": [
    "<H3>1.7 Exploring some samples</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa50dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [7]\n",
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [3]\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "test_prediction(0, W1, b1, W2, b2)\n",
    "test_prediction(1, W1, b1, W2, b2)\n",
    "test_prediction(2, W1, b1, W2, b2)\n",
    "test_prediction(50, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489e39c",
   "metadata": {},
   "source": [
    "<H2>Part 2: Error Analysis and Performance Improvements</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b9c4e",
   "metadata": {},
   "source": [
    "Based on the neural network, you should recommend some next steps in this part. Some ideas include investigating where the model fails to predict and/or trying to improve the model performance through, for example, different activation functions, expanding the network complexity.\n",
    "\n",
    "**It is crucial to provide reasoning behind what you do, or else no credit will be given.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9edc21",
   "metadata": {},
   "source": [
    "### Analyze your results, understand the model weakness, optimize your model and/or collect more data\n",
    " \n",
    "**Analyze Results**\n",
    "\n",
    "The initial neural network shows promise with a training accuracy of 82.94%. However, there are signs of potential overfitting, as evidenced by a slightly lower validation accuracy of 77.00%.\n",
    "\n",
    "**Understand Model Weakness(es)**\n",
    "\n",
    "To gain insight into the model's weaknesses and pinpoint where it falls short, I started by constructing and interpreting a confusion matrix and classification report to identify instances of misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "914e3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[41  0  2  1  1  1  1  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 27  0  9  0  3  0  1  0]\n",
      " [ 1  0  0 36  0  0  1  0  1  0]\n",
      " [ 0  1  5  5 23  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  3  1  4]\n",
      " [ 7  0 11  4  5  1  6  0  3  0]\n",
      " [ 0  0  0  0  0  4  0 32  0  5]\n",
      " [ 0  0  3  1  0  0  1  1 39  0]\n",
      " [ 0  0  0  0  0  1  0  3  0 43]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85        47\n",
      "           1       0.97      1.00      0.98        31\n",
      "           2       0.56      0.66      0.61        41\n",
      "           3       0.77      0.92      0.84        39\n",
      "           4       0.61      0.68      0.64        34\n",
      "           5       0.81      0.79      0.80        38\n",
      "           6       0.50      0.16      0.24        37\n",
      "           7       0.82      0.78      0.80        41\n",
      "           8       0.87      0.87      0.87        45\n",
      "           9       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.75      0.76      0.75       400\n",
      "weighted avg       0.76      0.77      0.75       400\n",
      "\n",
      "\n",
      "Top 3 most common errors:\n",
      "True Label: 6, Predicted Label: 2, Count: 11\n",
      "True Label: 2, Predicted Label: 4, Count: 9\n",
      "True Label: 6, Predicted Label: 0, Count: 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_misclassifications(predictions, true_labels, X_data):\n",
    "    # Initialize confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Purples)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(set(true_labels)))\n",
    "    plt.xticks(tick_marks, tick_marks)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    print()\n",
    "\n",
    "    # Find misclassifications\n",
    "    misclassifications = [(true_labels[i], predictions[i]) for i in range(len(predictions)) if predictions[i] != true_labels[i]]\n",
    "    \n",
    "    # Count misclassifications\n",
    "    error_counts = Counter(misclassifications)\n",
    "    \n",
    "    # Print top 3 most common errors\n",
    "    print(\"Top 3 most common errors:\")\n",
    "    for error, count in error_counts.most_common(3):\n",
    "        true_label, predicted_label = error\n",
    "        print(f\"True Label: {true_label}, Predicted Label: {predicted_label}, Count: {count}\")\n",
    "\n",
    "analyze_misclassifications(dev_predictions, Y_dev, X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7daf4",
   "metadata": {},
   "source": [
    "The confusion matrix and classification report indicates that the model exhibits significant confusion between certain clothing categories, notably (2) Pullover and (4) Coat, as well as (6) Shirt and (2) Pullover. This confusion is sensible given the visual similarities between these items; for instance, distinguishing a Pullover from a Coat, or a Shirt from a Pullover, can be challenging due to overlapping characteristics like sleeve length, texture, and style. Consequently, it's unsurprising that these pairs are the top three most common errors, reflecting the inherent complexity of the classification task.\n",
    "\n",
    "To mitigate these model weaknesses, we could apply Data Augmentation, adding additional diverse examples of the problematic class differentiations. Providing the model with more varied instances to learn from would improve its ability to distinguish between similar classes such as (2) Pullover and (4) Coat, and (6) Shirt and (2) Pullover. \n",
    "\n",
    "Additionally, techniques like fine-tuning the model architecture to emphasize subtle distinguishing features or adjusting class weights to assign higher penalties for misclassifications in critical areas could improve performance.\n",
    "\n",
    "**Model Optimization and/or Collecting More Data**\n",
    "\n",
    "To address overfitting and improve generalization, various optimization techniques such as L1/L2 regularization, dropout, or early stopping can be applied during training. I opted for L2 regularization due to its ability to effectively prevent overfitting by penalizing large weights, thus balancing model complexity and simplicity while promoting generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f74ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy: 11.94%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 38.00%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 49.94%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 56.31%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 60.81%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 63.75%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 66.25%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 67.69%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 69.31%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 70.31%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 71.12%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 71.75%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 72.81%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 73.50%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 74.19%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 75.12%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 74.12%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 74.56%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 75.31%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 75.94%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 76.31%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 76.62%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 76.88%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 77.19%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 77.88%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 77.94%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 78.44%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 78.81%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 79.06%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 79.00%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 78.88%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 79.19%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 79.62%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 79.88%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 80.25%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 80.31%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 80.50%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 80.56%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 80.88%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 81.00%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 81.44%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 81.56%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 81.56%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 82.12%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.19%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 82.31%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 82.50%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 82.75%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 82.94%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 82.94%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 83.19%\n",
      "\n",
      "Iteration:  0\n",
      "Accuracy: 9.00%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 40.00%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 53.25%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 62.50%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 65.88%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 67.88%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 69.69%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 70.44%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 71.31%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 72.00%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 72.62%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 72.94%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 73.62%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 74.12%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 73.94%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 74.19%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 75.06%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 75.44%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 75.88%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 76.31%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 77.00%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 77.50%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 77.94%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 78.12%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 78.44%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 78.69%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 79.06%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 79.38%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 79.62%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 80.12%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 80.25%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 80.25%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 80.38%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 80.44%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 80.50%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 80.94%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 81.06%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 81.38%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 81.75%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 81.88%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 81.94%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 81.94%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 81.94%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 82.19%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.19%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 82.25%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 82.44%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 82.50%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 82.50%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 82.56%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 82.88%\n",
      "\n",
      "Iteration:  0\n",
      "Accuracy: 14.31%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 44.94%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 54.00%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 57.75%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 61.06%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 63.56%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 65.12%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 66.94%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 67.88%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 68.94%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 69.75%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 69.62%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 70.19%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 70.94%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 71.81%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 72.25%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 72.69%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 73.12%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 73.75%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 73.94%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 74.06%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 74.25%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 74.38%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 74.44%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 74.69%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 75.25%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 75.50%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 75.69%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 76.25%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 76.81%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 77.12%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 77.62%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 77.56%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 77.69%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 78.25%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 78.31%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 78.19%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 78.12%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 78.44%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 78.44%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 78.75%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 78.94%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 79.38%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 79.56%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 80.00%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 80.31%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 80.44%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 80.75%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 80.75%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 80.94%\n",
      "\n",
      "Iteration:  0\n",
      "Accuracy: 12.06%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 40.69%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 54.87%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 60.50%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 64.50%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 66.19%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 67.19%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 64.88%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 67.31%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 68.94%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 70.75%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 71.50%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 72.19%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 73.19%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 74.00%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 74.75%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 75.12%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 75.88%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 75.94%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 76.62%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 76.94%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 77.25%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 77.81%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 77.81%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 78.00%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 78.25%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 78.50%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 78.69%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 78.88%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 79.25%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 79.50%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 79.75%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 79.81%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 80.06%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 80.38%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 80.50%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 80.50%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 80.75%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 81.06%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 81.25%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 81.62%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 81.88%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 82.06%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 82.38%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.50%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 82.62%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 82.94%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 83.12%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 83.56%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 83.69%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 83.94%\n",
      "\n",
      "Iteration:  0\n",
      "Accuracy: 19.44%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 44.94%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 56.25%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 61.25%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 64.75%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 66.38%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 64.94%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 67.12%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 68.06%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 69.88%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 70.50%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 70.94%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 72.31%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 73.00%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 73.56%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 73.94%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 74.94%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 75.31%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 76.12%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 76.50%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 76.94%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 77.44%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 78.00%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 78.38%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 78.50%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 78.69%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 78.88%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 79.12%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 79.69%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 80.06%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 80.19%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 80.50%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 80.69%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 80.88%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 81.06%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 81.44%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 81.50%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 81.38%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 81.69%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 81.81%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 82.19%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 82.44%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 82.62%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 82.81%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.88%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 83.00%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 83.19%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 83.38%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 83.50%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 83.62%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 83.69%\n",
      "\n",
      "Iteration:  0\n",
      "Accuracy: 18.94%\n",
      "\n",
      "Iteration:  10\n",
      "Accuracy: 37.75%\n",
      "\n",
      "Iteration:  20\n",
      "Accuracy: 49.88%\n",
      "\n",
      "Iteration:  30\n",
      "Accuracy: 56.06%\n",
      "\n",
      "Iteration:  40\n",
      "Accuracy: 60.12%\n",
      "\n",
      "Iteration:  50\n",
      "Accuracy: 62.88%\n",
      "\n",
      "Iteration:  60\n",
      "Accuracy: 64.31%\n",
      "\n",
      "Iteration:  70\n",
      "Accuracy: 64.81%\n",
      "\n",
      "Iteration:  80\n",
      "Accuracy: 66.31%\n",
      "\n",
      "Iteration:  90\n",
      "Accuracy: 67.81%\n",
      "\n",
      "Iteration:  100\n",
      "Accuracy: 69.25%\n",
      "\n",
      "Iteration:  110\n",
      "Accuracy: 70.56%\n",
      "\n",
      "Iteration:  120\n",
      "Accuracy: 71.44%\n",
      "\n",
      "Iteration:  130\n",
      "Accuracy: 71.81%\n",
      "\n",
      "Iteration:  140\n",
      "Accuracy: 72.44%\n",
      "\n",
      "Iteration:  150\n",
      "Accuracy: 72.75%\n",
      "\n",
      "Iteration:  160\n",
      "Accuracy: 73.44%\n",
      "\n",
      "Iteration:  170\n",
      "Accuracy: 73.94%\n",
      "\n",
      "Iteration:  180\n",
      "Accuracy: 74.38%\n",
      "\n",
      "Iteration:  190\n",
      "Accuracy: 74.94%\n",
      "\n",
      "Iteration:  200\n",
      "Accuracy: 75.31%\n",
      "\n",
      "Iteration:  210\n",
      "Accuracy: 75.88%\n",
      "\n",
      "Iteration:  220\n",
      "Accuracy: 75.94%\n",
      "\n",
      "Iteration:  230\n",
      "Accuracy: 76.19%\n",
      "\n",
      "Iteration:  240\n",
      "Accuracy: 76.56%\n",
      "\n",
      "Iteration:  250\n",
      "Accuracy: 77.00%\n",
      "\n",
      "Iteration:  260\n",
      "Accuracy: 77.31%\n",
      "\n",
      "Iteration:  270\n",
      "Accuracy: 77.75%\n",
      "\n",
      "Iteration:  280\n",
      "Accuracy: 78.31%\n",
      "\n",
      "Iteration:  290\n",
      "Accuracy: 78.81%\n",
      "\n",
      "Iteration:  300\n",
      "Accuracy: 79.19%\n",
      "\n",
      "Iteration:  310\n",
      "Accuracy: 79.31%\n",
      "\n",
      "Iteration:  320\n",
      "Accuracy: 79.44%\n",
      "\n",
      "Iteration:  330\n",
      "Accuracy: 79.31%\n",
      "\n",
      "Iteration:  340\n",
      "Accuracy: 79.69%\n",
      "\n",
      "Iteration:  350\n",
      "Accuracy: 79.81%\n",
      "\n",
      "Iteration:  360\n",
      "Accuracy: 80.19%\n",
      "\n",
      "Iteration:  370\n",
      "Accuracy: 80.31%\n",
      "\n",
      "Iteration:  380\n",
      "Accuracy: 80.56%\n",
      "\n",
      "Iteration:  390\n",
      "Accuracy: 80.88%\n",
      "\n",
      "Iteration:  400\n",
      "Accuracy: 81.31%\n",
      "\n",
      "Iteration:  410\n",
      "Accuracy: 81.62%\n",
      "\n",
      "Iteration:  420\n",
      "Accuracy: 81.75%\n",
      "\n",
      "Iteration:  430\n",
      "Accuracy: 81.88%\n",
      "\n",
      "Iteration:  440\n",
      "Accuracy: 82.12%\n",
      "\n",
      "Iteration:  450\n",
      "Accuracy: 82.31%\n",
      "\n",
      "Iteration:  460\n",
      "Accuracy: 82.38%\n",
      "\n",
      "Iteration:  470\n",
      "Accuracy: 82.38%\n",
      "\n",
      "Iteration:  480\n",
      "Accuracy: 82.56%\n",
      "\n",
      "Iteration:  490\n",
      "Accuracy: 82.81%\n",
      "\n",
      "Iteration:  500\n",
      "Accuracy: 82.94%\n",
      "\n",
      "Best Accuracy on Development Set: 80.00% (achieved with lambda_reg=0.5)\n"
     ]
    }
   ],
   "source": [
    "# Implement backward propagation with regularization\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y, lambda_reg):\n",
    "    # Convert Y to one-hot encoding\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    m = Y.shape[0]  # Number of training examples\n",
    "    \n",
    "    # Backward pass for the second layer\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T) + (lambda_reg / m) * W2  # Add L2 regularization to weights\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Backward pass for the first layer\n",
    "    dZ1 = np.dot(W2.T, dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T) + (lambda_reg / m) * W1  # Add L2 regularization to weights\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Perform gradient descent with regularization\n",
    "def gradient_descent(X, Y, alpha, iterations, lambda_reg):\n",
    "    # Initialize parameters\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Forward propagation\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        \n",
    "        # Backward propagation\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y, lambda_reg)\n",
    "        \n",
    "        # Update parameters\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "        # Print accuracy every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            accuracy = get_accuracy(predictions, Y)\n",
    "            print(\"Accuracy: {:.2f}%\\n\".format(accuracy))  # Print accuracy\n",
    "            \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "best_accuracy = 0  # Initialize best accuracy\n",
    "best_lambda_reg = None  # Initialize best lambda_reg\n",
    "\n",
    "# Define regularization strengths to try\n",
    "lambda_regs = [0.001, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "\n",
    "# Iterate over each regularization strength\n",
    "for lambda_reg in lambda_regs:\n",
    "    # Perform gradient descent with current lambda_reg\n",
    "    W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 501, lambda_reg=lambda_reg)\n",
    "    \n",
    "    # Make predictions on development set\n",
    "    dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "    \n",
    "    # Calculate accuracy on development set\n",
    "    dev_accuracy = get_accuracy(dev_predictions, Y_dev)\n",
    "    \n",
    "    # Update best accuracy and lambda_reg\n",
    "    if dev_accuracy > best_accuracy:\n",
    "        best_accuracy = dev_accuracy\n",
    "        best_lambda_reg = lambda_reg\n",
    "\n",
    "# Print the best outcome\n",
    "print(\"Best Accuracy on Development Set: {:.2f}% (achieved with lambda_reg={})\".format(best_accuracy, best_lambda_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3689c",
   "metadata": {},
   "source": [
    "Applying L2 regularization with a moderate strength improved the model's generalization performance on unseen data, slightly mitigating overfitting. The best accuracy achieved on the development set was 80.00%, achieved with a lambda_reg value of 0.5.\n",
    "\n",
    "Finally, collecting more diverse and representative data can further improve the model's performance by providing it with a richer set of examples to learn from. Acquiring additional images of clothing items across different styles, textures, and variations will ensure that the model learns to generalize well across the entire spectrum of clothing categories.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "While recognizing the potential for further improvement, I am confident in presenting this model as a strong foundation. Through analysis, strategic optimization, and exploration of potential enhancements, I believe that the constructed neural network will deliver dependable classification accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
